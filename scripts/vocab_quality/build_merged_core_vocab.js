#!/usr/bin/env node
const fs = require("fs");
const path = require("path");

const ROOT = process.cwd();
const SRC_ROOT = path.join(ROOT, "js", "vocabularies");
const OUT_DIR = path.join(ROOT, "js", "vocabularies", "normalized");
const REPORT_DIR = path.join(ROOT, "reports", "vocab");

const INCLUDE_SEGMENTS = [
  `${path.sep}minecraft${path.sep}`,
  `${path.sep}stage${path.sep}`,
  `${path.sep}kindergarten${path.sep}`,
  `${path.sep}common${path.sep}`,
];

const EXCLUDE_SEGMENTS = [
  "backup",
  "cleanup_backups",
  "backups",
  "node_modules",
  "game_vocabularies",
  "mappings.js",
  "merge_vocabularies.js",
  `${path.sep}normalized${path.sep}`,
];

function walk(dir) {
  const out = [];
  for (const entry of fs.readdirSync(dir, { withFileTypes: true })) {
    const full = path.join(dir, entry.name);
    if (EXCLUDE_SEGMENTS.some((x) => full.includes(x))) continue;
    if (entry.isDirectory()) out.push(...walk(full));
    else if (entry.isFile() && entry.name.endsWith(".js")) out.push(full);
  }
  return out;
}

function normalizeWord(s) {
  return String(s || "")
    .trim()
    .toLowerCase()
    .replace(/\s+/g, " ");
}

function extractArrayLiteral(text) {
  // Match first top-level const array assignment: const XXX = [ ... ];
  const m = text.match(/const\s+[A-Za-z0-9_]+\s*=\s*(\[[\s\S]*\])\s*;?\s*$/m);
  if (!m) return null;
  return m[1];
}

function loadArrayFromFile(file) {
  try {
    const text = fs.readFileSync(file, "utf8");
    const literal = extractArrayLiteral(text);
    if (!literal) return null;
    // Data-only files, evaluate as array literal.
    // eslint-disable-next-line no-new-func
    const arr = new Function(`return (${literal});`)();
    if (!Array.isArray(arr)) return null;
    return arr;
  } catch {
    return null;
  }
}

function scoreEntry(e) {
  let s = 0;
  if (e && e.chinese) s += 3;
  if (e && e.phonetic) s += 1;
  if (e && e.phrase) s += 1;
  if (e && Array.isArray(e.imageURLs) && e.imageURLs.length > 0) s += 2;
  if (e && e.difficulty) s += 1;
  if (e && e.category) s += 1;
  return s;
}

function mergeEntry(base, incoming) {
  const out = { ...base };
  for (const k of Object.keys(incoming || {})) {
    const v = incoming[k];
    if (v === undefined || v === null) continue;
    if (Array.isArray(v)) {
      if (!Array.isArray(out[k]) || out[k].length === 0) out[k] = v;
      continue;
    }
    if (typeof v === "string") {
      if (!out[k] || String(out[k]).trim() === "") out[k] = v;
      continue;
    }
    if (typeof out[k] === "undefined") out[k] = v;
  }
  return out;
}

function main() {
  fs.mkdirSync(OUT_DIR, { recursive: true });
  fs.mkdirSync(REPORT_DIR, { recursive: true });

  const files = walk(SRC_ROOT).filter((f) => INCLUDE_SEGMENTS.some((seg) => f.includes(seg)));
  const pool = [];
  for (const file of files) {
    const arr = loadArrayFromFile(file);
    if (!arr) continue;
    for (const item of arr) {
      if (!item || typeof item !== "object") continue;
      const key = normalizeWord(item.standardized || item.word);
      if (!key) continue;
      pool.push({
        key,
        item,
        file: path.relative(ROOT, file),
      });
    }
  }

  const groups = new Map();
  for (const row of pool) {
    if (!groups.has(row.key)) groups.set(row.key, []);
    groups.get(row.key).push(row);
  }

  const merged = [];
  const clusterRows = [];
  for (const [key, rows] of groups.entries()) {
    rows.sort((a, b) => scoreEntry(b.item) - scoreEntry(a.item));
    let canonical = { ...rows[0].item };
    const sources = new Set([rows[0].file]);
    for (let i = 1; i < rows.length; i++) {
      canonical = mergeEntry(canonical, rows[i].item);
      sources.add(rows[i].file);
    }
    canonical.standardized = canonical.standardized || canonical.word || key;
    canonical.word = canonical.word || canonical.standardized;
    canonical._sources = [...sources];
    merged.push(canonical);
    if (rows.length > 1) {
      clusterRows.push({
        key,
        occurrences: rows.length,
        files: [...new Set(rows.map((r) => r.file))].length,
      });
    }
  }

  merged.sort((a, b) => normalizeWord(a.standardized).localeCompare(normalizeWord(b.standardized)));
  clusterRows.sort((a, b) => b.occurrences - a.occurrences);

  const outJs = `// Auto-generated by scripts/vocab_quality/build_merged_core_vocab.js\nconst CORE_MERGED_DEDUP = ${JSON.stringify(
    merged,
    null,
    2
  )};\n`;
  fs.writeFileSync(path.join(OUT_DIR, "core_merged_dedup.js"), outJs, "utf8");

  const csv = ["key,occurrences,files"];
  for (const r of clusterRows) csv.push(`${r.key},${r.occurrences},${r.files}`);
  fs.writeFileSync(path.join(REPORT_DIR, "merge_clusters.csv"), csv.join("\n"), "utf8");

  const summary = {
    generatedAt: new Date().toISOString(),
    scannedFiles: files.length,
    rawRows: pool.length,
    uniqueKeys: groups.size,
    dedupOutput: merged.length,
    duplicateClusters: clusterRows.length,
    outputFile: "js/vocabularies/normalized/core_merged_dedup.js",
  };
  fs.writeFileSync(path.join(REPORT_DIR, "merge_summary.json"), JSON.stringify(summary, null, 2), "utf8");
  console.log(JSON.stringify(summary, null, 2));
}

main();


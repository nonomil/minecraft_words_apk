#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è‡ªåŠ¨ä¿®å¤è¢«é˜»æ­¢çš„URL
å°†Fandomç­‰è¢«é˜»æ­¢çš„é“¾æ¥æ›¿æ¢ä¸ºTwemoji CDNé“¾æ¥
"""

import os
import json
import re
import argparse
from collections import defaultdict

class URLAutoFixer:
    def __init__(self, base_dir):
        self.base_dir = base_dir
        self.fix_suggestions_file = os.path.join(base_dir, 'url_fix_suggestions.json')
        self.backup_dir = os.path.join(base_dir, 'backups')
        
    def load_fix_suggestions(self):
        """åŠ è½½ä¿®å¤å»ºè®®"""
        if not os.path.exists(self.fix_suggestions_file):
            print(f"[AutoFix] ä¿®å¤å»ºè®®æ–‡ä»¶ä¸å­˜åœ¨: {self.fix_suggestions_file}")
            return []
            
        with open(self.fix_suggestions_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def create_backup(self, file_path):
        """åˆ›å»ºæ–‡ä»¶å¤‡ä»½"""
        if not os.path.exists(self.backup_dir):
            os.makedirs(self.backup_dir)
            
        backup_name = os.path.basename(file_path) + '.backup'
        backup_path = os.path.join(self.backup_dir, backup_name)
        
        with open(file_path, 'r', encoding='utf-8') as src:
            with open(backup_path, 'w', encoding='utf-8') as dst:
                dst.write(src.read())
                
        return backup_path
    
    def fix_file(self, file_path, url_replacements, dry_run=False):
        """ä¿®å¤å•ä¸ªæ–‡ä»¶ä¸­çš„URL"""
        full_path = os.path.join(self.base_dir, file_path)
        
        if not os.path.exists(full_path):
            print(f"[AutoFix] æ–‡ä»¶ä¸å­˜åœ¨: {full_path}")
            return False
            
        # è¯»å–æ–‡ä»¶å†…å®¹
        with open(full_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # è®¡ç®—å°†è¦æ›¿æ¢çš„æ•°é‡
        replacements_planned = 0
        for old_url, new_url in url_replacements.items():
            if old_url in content:
                replacements_planned += 1
                new_host = os.path.basename(new_url) if new_url.startswith('http') else new_url
                print(f"[AutoFix] è®¡åˆ’æ›¿æ¢: {old_url} -> {new_url}")
        
        if dry_run:
            if replacements_planned > 0:
                print(f"[AutoFix] DRY-RUN: {file_path} å°†æ›¿æ¢ {replacements_planned} ä¸ªURL (æœªå†™å…¥ï¼Œæœªå¤‡ä»½)")
                return True
            else:
                print(f"[AutoFix] DRY-RUN: {file_path} æ— éœ€ä¿®å¤")
                return False
        
        # åˆ›å»ºå¤‡ä»½
        backup_path = self.create_backup(full_path)
        print(f"[AutoFix] å·²å¤‡ä»½: {backup_path}")
        
        # æ‰§è¡Œæ›¿æ¢
        replacements_made = 0
        for old_url, new_url in url_replacements.items():
            if old_url in content:
                content = content.replace(old_url, new_url)
                replacements_made += 1
                # è¾“å‡ºæ›´å‡†ç¡®çš„ç›®æ ‡æ ‡è¯†
                dest = new_url
                print(f"[AutoFix] æ›¿æ¢: {old_url} -> {dest}")
        
        # å†™å›æ–‡ä»¶
        if replacements_made > 0:
            with open(full_path, 'w', encoding='utf-8') as f:
                f.write(content)
            print(f"[AutoFix] å·²ä¿®å¤ {file_path}: {replacements_made} ä¸ªURL")
            return True
        else:
            print(f"[AutoFix] æ— éœ€ä¿®å¤: {file_path}")
            return False
    
    def run_auto_fix(self, statuses=None, dry_run=False):
        """è¿è¡Œè‡ªåŠ¨ä¿®å¤"""
        statuses = statuses or ['blocked', 'not_found', 'variant_ok']
        print("[AutoFix] å¼€å§‹è‡ªåŠ¨ä¿®å¤URL...")
        print(f"[AutoFix] è¿‡æ»¤çŠ¶æ€: {', '.join(statuses)}  | æ¨¡å¼: {'DRY-RUN' if dry_run else 'APPLY'}")
        
        # åŠ è½½ä¿®å¤å»ºè®®
        suggestions = self.load_fix_suggestions()
        if not suggestions:
            print("[AutoFix] æ²¡æœ‰æ‰¾åˆ°ä¿®å¤å»ºè®®")
            return
            
        # æŒ‰æ–‡ä»¶åˆ†ç»„ä¿®å¤å»ºè®®
        file_fixes = defaultdict(dict)
        
        for suggestion in suggestions:
            status = suggestion.get('status')
            if status not in statuses:
                continue
            
            original_url = suggestion.get('original_url')
            replacement_url = suggestion.get('suggested_replacement')
            affected_files = suggestion.get('affected_files', [])
            
            # ç¼ºå°‘æ›¿ä»£é“¾æ¥åˆ™è·³è¿‡
            if not original_url or not replacement_url:
                print(f"[AutoFix] è·³è¿‡ï¼ˆç¼ºå°‘æ›¿æ¢ä¿¡æ¯ï¼‰: {original_url}")
                continue
            
            for file_path in affected_files:
                file_fixes[file_path][original_url] = replacement_url
        
        print(f"[AutoFix] éœ€è¦ä¿®å¤ {len(file_fixes)} ä¸ªæ–‡ä»¶")
        
        # é€æ–‡ä»¶æ‰§è¡Œä¿®å¤
        fixed_files = 0
        total_replacements = 0
        
        for file_path, url_replacements in file_fixes.items():
            if self.fix_file(file_path, url_replacements, dry_run=dry_run):
                fixed_files += 1
                total_replacements += len(url_replacements)
        
        print(f"\n[AutoFix] ä¿®å¤{'é¢„è§ˆ' if dry_run else 'å®Œæˆ'}:")
        print(f"  ğŸ“ å½±å“æ–‡ä»¶æ•°: {fixed_files}")
        print(f"  ğŸ”— æ›¿æ¢URLæ•°: {total_replacements}")
        if not dry_run:
            print(f"  ğŸ’¾ å¤‡ä»½ç›®å½•: {self.backup_dir}")
        
        return fixed_files > 0
    
    def preview_fixes(self, statuses=None):
        """é¢„è§ˆå°†è¦è¿›è¡Œçš„ä¿®å¤"""
        statuses = statuses or ['blocked', 'not_found', 'variant_ok']
        suggestions = self.load_fix_suggestions()
        if not suggestions:
            return 0
            
        print("[AutoFix] ä¿®å¤é¢„è§ˆ:")
        print("=" * 60)
        
        count = 0
        for suggestion in suggestions:
            if suggestion.get('status') not in statuses:
                continue
            count += 1
            print(f"\næ–‡ä»¶: {', '.join(suggestion.get('affected_files', []))}")
            print(f"åŸURL: {suggestion.get('original_url')}")
            print(f"æ–°URL: {suggestion.get('suggested_replacement')}")
            print(f"é—®é¢˜: {suggestion.get('issue', '')}")
        
        print(f"\næ€»è®¡éœ€è¦ä¿®å¤ {count} ä¸ªURLï¼ˆçŠ¶æ€: {', '.join(statuses)}ï¼‰")
        return count


def parse_statuses(s):
    if not s:
        return ['blocked', 'not_found', 'variant_ok']
    return [x.strip() for x in s.split(',') if x.strip()]


def main():
    parser = argparse.ArgumentParser(description='è‡ªåŠ¨ä¿®å¤ URLï¼ˆåŸºäºé«˜çº§å¥åº·æ£€æŸ¥å»ºè®®ï¼‰')
    parser.add_argument('--statuses', type=str, default='blocked,not_found,variant_ok', help='è¦ä¿®å¤çš„çŠ¶æ€ï¼Œé€—å·åˆ†éš”ï¼Œå¦‚: blocked,not_found,variant_ok')
    parser.add_argument('--dry-run', action='store_true', help='ä»…é¢„è§ˆæ›´æ”¹ï¼Œä¸å†™å…¥æ–‡ä»¶ã€ä¸åˆ›å»ºå¤‡ä»½')
    args = parser.parse_args()

    base_dir = os.path.dirname(os.path.abspath(__file__))
    fixer = URLAutoFixer(base_dir)
    statuses = parse_statuses(args.statuses)
    
    # é¢„è§ˆä¿®å¤
    to_fix_count = fixer.preview_fixes(statuses=statuses)
    
    if to_fix_count > 0:
        if args.dry_run:
            print("\n[AutoFix] DRY-RUN ç»“æŸã€‚è‹¥è¦å®é™…æ‰§è¡Œä¿®å¤ï¼Œè¯·å»æ‰ --dry-run æ ‡å¿—ã€‚")
            return
        print("\n[AutoFix] å¼€å§‹æ‰§è¡Œä¿®å¤...")
        success = fixer.run_auto_fix(statuses=statuses, dry_run=False)
        
        if success:
            print("\n[AutoFix] âœ… ä¿®å¤å®Œæˆï¼å»ºè®®é‡æ–°è¿è¡Œå¥åº·æ£€æŸ¥éªŒè¯ç»“æœã€‚")
        else:
            print("\n[AutoFix] âŒ ä¿®å¤å¤±è´¥æˆ–æ— éœ€ä¿®å¤ã€‚")
    else:
        print("\n[AutoFix] æ²¡æœ‰å‘ç°éœ€è¦ä¿®å¤çš„URLã€‚")

if __name__ == '__main__':
    main()
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é«˜çº§å›¾ç‰‡URLå¥åº·æ£€æŸ¥è„šæœ¬
ä¸“é—¨æ£€æµ‹é˜²æœºå™¨è®¿é—®ã€403é”™è¯¯ã€è¶…æ—¶ç­‰é—®é¢˜
å¹¶ä¸ºæœ‰é—®é¢˜çš„é“¾æ¥æä¾›Twemojiæ›¿ä»£æ–¹æ¡ˆ
"""

import os
import re
import json
import time
import requests
from urllib.parse import urlparse
from concurrent.futures import ThreadPoolExecutor, as_completed
from collections import defaultdict

class AdvancedURLHealthChecker:
    def __init__(self, base_dir):
        self.base_dir = base_dir
        self.session = requests.Session()
        # è®¾ç½®æ›´çœŸå®çš„User-Agent
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.5',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
        })
        self.timeout = 10
        self.problematic_domains = set()
        self.url_status = {}
        
    def extract_urls_from_js_files(self):
        """ä»JSæ–‡ä»¶ä¸­æå–æ‰€æœ‰å›¾ç‰‡URL"""
        url_sources = defaultdict(list)
        js_files = []
        
        for root, dirs, files in os.walk(self.base_dir):
            for file in files:
                if file.endswith('.js') and not file.startswith('.'):
                    js_files.append(os.path.join(root, file))
        
        print(f"[AdvancedCheck] æ‰«æåˆ° {len(js_files)} ä¸ªJSæ–‡ä»¶")
        
        for js_file in js_files:
            try:
                with open(js_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                    
                # æå–imageURLsæ•°ç»„ä¸­çš„URL
                url_pattern = r'"url"\s*:\s*"([^"]+)"'
                urls = re.findall(url_pattern, content)
                
                # ä¹Ÿæå–ç›´æ¥çš„imageURLsæ•°ç»„
                direct_pattern = r'imageURLs\s*:\s*\[\s*"([^"]+)"'
                direct_urls = re.findall(direct_pattern, content)
                
                all_urls = urls + direct_urls
                
                for url in all_urls:
                    if url.startswith('http'):
                        url_sources[url].append(os.path.relpath(js_file, self.base_dir))
                        
            except Exception as e:
                print(f"[AdvancedCheck] è¯»å–æ–‡ä»¶å¤±è´¥ {js_file}: {e}")
                
        return url_sources
    
    def check_url_health(self, url):
        """æ£€æŸ¥å•ä¸ªURLçš„å¥åº·çŠ¶æ€"""
        try:
            response = self.session.head(url, timeout=self.timeout, allow_redirects=True)
            status_code = response.status_code

            # æŸäº›ç«™ç‚¹å¯¹ HEAD ä¸å‹å¥½ï¼Œå°è¯• GET å…œåº•
            if status_code != 200:
                try:
                    get_resp = self.session.get(url, timeout=self.timeout, allow_redirects=True)
                    if get_resp.status_code == 200:
                        return {'url': url, 'status': 'healthy', 'code': 200}
                    else:
                        status_code = get_resp.status_code
                except Exception:
                    pass

            if status_code == 200:
                return {'url': url, 'status': 'healthy', 'code': status_code}
            elif status_code in (403, 404):
                # å¯¹ MediaWiki é£æ ¼é“¾æ¥å°è¯• FilePath/Redirect å˜ä½“
                variants = self.probe_mediawiki_variants(url)
                for v_url in variants:
                    try:
                        v_head = self.session.head(v_url, timeout=self.timeout, allow_redirects=True)
                        if v_head.status_code == 200:
                            return {'url': url, 'status': 'variant_ok', 'code': 200, 'resolved_url': v_url}
                        # HEAD ä¸å‹å¥½å†è¯• GET
                        v_get = self.session.get(v_url, timeout=self.timeout, allow_redirects=True)
                        if v_get.status_code == 200:
                            return {'url': url, 'status': 'variant_ok', 'code': 200, 'resolved_url': v_url}
                    except Exception:
                        continue
                return {'url': url, 'status': 'blocked' if status_code == 403 else 'not_found', 'code': status_code, 'issue': 'Access Forbidden - å¯èƒ½é˜²æœºå™¨è®¿é—®' if status_code == 403 else 'Resource Not Found'}
            elif status_code in [429, 503]:
                return {'url': url, 'status': 'rate_limited', 'code': status_code, 'issue': 'Rate Limited or Service Unavailable'}
            else:
                return {'url': url, 'status': 'error', 'code': status_code, 'issue': f'HTTP {status_code}'}

        except requests.exceptions.Timeout:
            return {'url': url, 'status': 'timeout', 'issue': 'Request Timeout'}
        except requests.exceptions.ConnectionError:
            return {'url': url, 'status': 'connection_error', 'issue': 'Connection Failed'}
        except Exception as e:
            return {'url': url, 'status': 'unknown_error', 'issue': str(e)}

    def generate_twemoji_alternative(self, original_url, context_info):
        """ä¸ºæœ‰é—®é¢˜çš„URLç”ŸæˆTwemojiæ›¿ä»£æ–¹æ¡ˆ"""
        # åŸºäºæ–‡ä»¶åæˆ–ä¸Šä¸‹æ–‡æ¨æ–­åˆé€‚çš„emoji
        url_lower = original_url.lower()

        # Animal Crossingè§’è‰²æ˜ å°„
        if 'tom_nook' in url_lower or 'tom-nook' in url_lower:
            return 'https://twemoji.maxcdn.com/v/latest/svg/1f99d.svg'  # ğŸ¦ raccoon
        elif 'isabelle' in url_lower:
            return 'https://twemoji.maxcdn.com/v/latest/svg/1f436.svg'  # ğŸ¶ dog
        elif 'blathers' in url_lower or 'celeste' in url_lower:
            return 'https://twemoji.maxcdn.com/v/latest/svg/1f989.svg'  # ğŸ¦‰ owl
        elif 'kk' in url_lower or 'slider' in url_lower:
            return 'https://twemoji.maxcdn.com/v/latest/svg/1f3b5.svg'  # ğŸµ music
        elif any(name in url_lower for name in ['mabel', 'sable', 'label']):
            return 'https://twemoji.maxcdn.com/v/latest/svg/1f994.svg'  # ğŸ¦” hedgehog
        elif any(name in url_lower for name in ['timmy', 'tommy']):
            return 'https://twemoji.maxcdn.com/v/latest/svg/1f99d.svg'  # ğŸ¦ raccoon
        elif 'gulliver' in url_lower:
            return 'https://twemoji.maxcdn.com/v/latest/svg/1f54a.svg'  # ğŸ•Šï¸ dove (closest to seagull)
        elif 'sahara' in url_lower:
            return 'https://twemoji.maxcdn.com/v/latest/svg/1f42a.svg'  # ğŸª camel
        elif 'redd' in url_lower:
            return 'https://twemoji.maxcdn.com/v/latest/svg/1f98a.svg'  # ğŸ¦Š fox
        elif 'flick' in url_lower:
            return 'https://twemoji.maxcdn.com/v/latest/svg/1f98e.svg'  # ğŸ¦ lizard
        elif 'pascal' in url_lower:
            return 'https://twemoji.maxcdn.com/v/latest/svg/1f9a6.svg'  # ğŸ¦¦ otter
        elif 'leif' in url_lower:
            return 'https://twemoji.maxcdn.com/v/latest/svg/1f9a5.svg'  # ğŸ¦¥ sloth
        elif 'kicks' in url_lower:
            return 'https://twemoji.maxcdn.com/v/latest/svg/1f9a8.svg'  # ğŸ¦¨ skunk
        
        # é€šç”¨åŠ¨ç‰©ç±»å‹
        elif any(animal in url_lower for animal in ['cat', 'feline']):
            return 'https://twemoji.maxcdn.com/v/latest/svg/1f431.svg'  # ğŸ± cat
        elif any(animal in url_lower for animal in ['dog', 'canine']):
            return 'https://twemoji.maxcdn.com/v/latest/svg/1f436.svg'  # ğŸ¶ dog
        elif any(animal in url_lower for animal in ['bear', 'cub']):
            return 'https://twemoji.maxcdn.com/v/latest/svg/1f43b.svg'  # ğŸ» bear
        elif any(animal in url_lower for animal in ['deer']):
            return 'https://twemoji.maxcdn.com/v/latest/svg/1f98c.svg'  # ğŸ¦Œ deer
        elif any(animal in url_lower for animal in ['wolf']):
            return 'https://twemoji.maxcdn.com/v/latest/svg/1f43a.svg'  # ğŸº wolf
        elif any(animal in url_lower for animal in ['sheep', 'lamb']):
            return 'https://twemoji.maxcdn.com/v/latest/svg/1f411.svg'  # ğŸ‘ sheep
        elif any(animal in url_lower for animal in ['squirrel']):
            return 'https://twemoji.maxcdn.com/v/latest/svg/1f43f.svg'  # ğŸ¿ï¸ squirrel
        elif any(animal in url_lower for animal in ['rhino']):
            return 'https://twemoji.maxcdn.com/v/latest/svg/1f98f.svg'  # ğŸ¦ rhino
        
        # é»˜è®¤é€šç”¨å›¾æ ‡
        return 'https://twemoji.maxcdn.com/v/latest/svg/1f3ae.svg'  # ğŸ® game controller
    
    def run_health_check(self):
        """è¿è¡Œå®Œæ•´çš„å¥åº·æ£€æŸ¥"""
        print("[AdvancedCheck] å¼€å§‹é«˜çº§URLå¥åº·æ£€æŸ¥...")
        start_time = time.time()
        
        # æå–æ‰€æœ‰URL
        url_sources = self.extract_urls_from_js_files()
        unique_urls = list(url_sources.keys())
        
        print(f"[AdvancedCheck] å‘ç° {len(unique_urls)} ä¸ªå”¯ä¸€URL")
        
        # å¹¶å‘æ£€æŸ¥URLå¥åº·çŠ¶æ€
        results = []
        with ThreadPoolExecutor(max_workers=10) as executor:
            future_to_url = {executor.submit(self.check_url_health, url): url for url in unique_urls}
            
            for future in as_completed(future_to_url):
                result = future.result()
                results.append(result)
                
                # å®æ—¶æ˜¾ç¤ºè¿›åº¦
                if len(results) % 20 == 0:
                    print(f"[AdvancedCheck] å·²æ£€æŸ¥ {len(results)}/{len(unique_urls)} ä¸ªURL")
        
        # åˆ†æç»“æœ
        healthy_count = sum(1 for r in results if r['status'] == 'healthy')
        blocked_count = sum(1 for r in results if r['status'] == 'blocked')
        error_count = len(results) - healthy_count
        
        print(f"\n[AdvancedCheck] æ£€æŸ¥å®Œæˆ:")
        print(f"  âœ… å¥åº·: {healthy_count}")
        print(f"  ğŸš« è¢«é˜»æ­¢: {blocked_count}")
        print(f"  âŒ å…¶ä»–é”™è¯¯: {error_count - blocked_count}")
        
        # ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
        self.generate_detailed_report(results, url_sources)
        
        # ç”Ÿæˆä¿®å¤å»ºè®®
        if blocked_count > 0 or error_count > 0:
            self.generate_fix_suggestions(results, url_sources)
        
        elapsed = time.time() - start_time
        print(f"[AdvancedCheck] æ€»è€—æ—¶: {elapsed:.2f}ç§’")
        
        return results
    
    def generate_detailed_report(self, results, url_sources):
        """ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š"""
        report_path = os.path.join(self.base_dir, 'advanced_url_health_report.txt')
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("é«˜çº§URLå¥åº·æ£€æŸ¥æŠ¥å‘Š\n")
            f.write("=" * 50 + "\n\n")
            
            # æŒ‰çŠ¶æ€åˆ†ç»„
            status_groups = defaultdict(list)
            for result in results:
                status_groups[result['status']].append(result)
            
            for status, items in status_groups.items():
                f.write(f"\n{status.upper()} ({len(items)} ä¸ª):\n")
                f.write("-" * 30 + "\n")
                
                for item in items:
                    f.write(f"URL: {item['url']}\n")
                    if 'code' in item:
                        f.write(f"çŠ¶æ€ç : {item['code']}\n")
                    if 'issue' in item:
                        f.write(f"é—®é¢˜: {item['issue']}\n")
                    
                    # æ˜¾ç¤ºä½¿ç”¨æ­¤URLçš„æ–‡ä»¶
                    files = url_sources.get(item['url'], [])
                    if files:
                        f.write(f"ä½¿ç”¨æ–‡ä»¶: {', '.join(files)}\n")
                    
                    f.write("\n")
        
        print(f"[AdvancedCheck] è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
    
    def probe_mediawiki_variants(self, url: str):
        """é’ˆå¯¹ MediaWiki é£æ ¼é“¾æ¥ï¼Œç”Ÿæˆ FilePath/Redirect ç›´é“¾å˜ä½“"""
        variants = []
        try:
            m = re.match(r'^(https?://[^/]+)/wiki/File:([^?#]+)', url, flags=re.IGNORECASE)
            if m:
                base, file = m.group(1), m.group(2)
                variants.append(f"{base}/wiki/Special:FilePath/{file}")
                variants.append(f"{base}/wiki/Special:Redirect/file/{file}")
                return variants
            m2 = re.match(r'^(https?://[^/]+)/wiki/[^?]+\?file=([^&#]+)', url, flags=re.IGNORECASE)
            if m2:
                base, file = m2.group(1), m2.group(2)
                try:
                    file = requests.utils.unquote(file)
                except Exception:
                    pass
                variants.append(f"{base}/wiki/Special:FilePath/{file}")
                variants.append(f"{base}/wiki/Special:Redirect/file/{file}")
                return variants
        except Exception:
            pass
        return variants

    def is_url_ok(self, url: str) -> bool:
        """å¿«é€Ÿåˆ¤æ–­URLæ˜¯å¦å¯è®¿é—®ï¼Œå…ˆHEADå†GETå…œåº•"""
        try:
            r = self.session.head(url, timeout=self.timeout, allow_redirects=True)
            if r.status_code == 200:
                return True
            g = self.session.get(url, timeout=self.timeout, allow_redirects=True)
            return g.status_code == 200
        except Exception:
            return False

    def generate_fix_suggestions(self, results, url_sources):
        """ç”Ÿæˆä¿®å¤å»ºè®®"""
        fix_path = os.path.join(self.base_dir, 'url_fix_suggestions.json')

        suggestions = []

        for result in results:
            if result['status'] != 'healthy':
                url = result['url']
                files = url_sources.get(url, [])

                # å¦‚æœåœ¨æ£€æŸ¥é˜¶æ®µå·²æ‰¾åˆ°å¯ç”¨å˜ä½“ï¼Œä¼˜å…ˆæ¨èè¯¥å˜ä½“
                replacement = result.get('resolved_url')
                replacement_reason = 'MediaWiki FilePath/Redirect ç›´é“¾æ›´ç¨³å®š'

                # è‹¥æœªæ‰¾åˆ°ï¼Œä¸”æ˜¯ MediaWiki é£æ ¼ï¼Œå°è¯•ç°åœºæ¢æµ‹å˜ä½“
                if not replacement:
                    variants = self.probe_mediawiki_variants(url)
                    for v in variants:
                        if self.is_url_ok(v):
                            replacement = v
                            break

                # è‹¥ä»æ— å¯ç”¨å˜ä½“ï¼Œå›é€€åˆ° Twemoji æ–¹æ¡ˆ
                if not replacement:
                    replacement = self.generate_twemoji_alternative(url, {'files': files})
                    replacement_reason = 'Twemoji CDN - ç¨³å®šä¸”æ— è®¿é—®é™åˆ¶'

                suggestion = {
                    'original_url': url,
                    'status': result['status'],
                    'issue': result.get('issue', ''),
                    'affected_files': files,
                    'suggested_replacement': replacement,
                    'replacement_reason': replacement_reason
                }

                suggestions.append(suggestion)

        with open(fix_path, 'w', encoding='utf-8') as f:
            json.dump(suggestions, f, indent=2, ensure_ascii=False)

        print(f"[AdvancedCheck] ä¿®å¤å»ºè®®å·²ä¿å­˜: {fix_path}")
        print(f"[AdvancedCheck] å‘ç° {len(suggestions)} ä¸ªéœ€è¦ä¿®å¤çš„URL")

def main():
    base_dir = os.path.dirname(os.path.abspath(__file__))
    checker = AdvancedURLHealthChecker(base_dir)
    checker.run_health_check()

if __name__ == '__main__':
    main()